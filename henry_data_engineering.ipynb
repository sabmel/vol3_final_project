{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Separate Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "End quarter is included as a row of mostly NANs. In column 'desc', this is noted as \"END QUARTER ...\", i.e. \"END QUARTER 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_games(df: pd.DataFrame) -> list[pd.DataFrame]:\n",
    "    \"\"\"Separate dataframe into separate games via the game ID. Place into a \n",
    "    list of games. Indices are reindexed so plays are numbered, starting with 0\n",
    "    \"\"\"\n",
    "    games = [df[df['GameID'] == value].reset_index(drop=True) for value in df['GameID'].unique()]\n",
    "        \n",
    "    return games\n",
    "\n",
    "def separate_years(df: pd.DataFrame) -> list[pd.DataFrame]:\n",
    "    \"\"\"Separates the games by which season in which they occured. Outputs a list of seasons.\"\"\"\n",
    "    seasons = [df[df['Season'] == value].reset_index(drop=True) for value in df['Season'].unique()]\n",
    "    \n",
    "    return seasons\n",
    "\n",
    "def calculate_time_per_play(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a new column which is the time each play took.\n",
    "    Kicks will have NANs in the new play_time column, which should make them easy to remove\n",
    "    \"\"\"\n",
    "    game['play_time'] = -game['TimeSecs'].diff()\n",
    "\n",
    "    return game\n",
    "\n",
    "\n",
    "def drop_unnecessary_rows(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"The end of each quarter is its own row. Same with timeouts\n",
    "    and the end of the game. Other values are mostly NANs.\n",
    "    This removes all of those unhelpful rows and reindexes\n",
    "\n",
    "    NOTE: plays must be indexed starting with their first play\n",
    "    TODO: Might be able to just drop rows with missing posteam\n",
    "    \"\"\"\n",
    "    # find indices\n",
    "    game.dropna(subset=['posteam', 'play_time'], inplace=True)\n",
    "    # reset index\n",
    "    game = game.reset_index(drop=True)\n",
    "\n",
    "    return game\n",
    "\n",
    "def encode_teams(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Change all team names to just 0s or 1s. This won't be retraceable if you are\n",
    "    looking for a game with a specific team playing.\n",
    "    \"\"\"\n",
    "    teams = game['posteam'].unique()\n",
    "    if len(teams) != 2:\n",
    "        print(teams)\n",
    "        raise ValueError(\"Dataset has not been properly cleaned. There are more than 2 values in posteam.\")\n",
    "    \n",
    "    team_map = {team:i for i, team in enumerate(teams)}\n",
    "    game['posteam'] = game['posteam'].map(team_map)\n",
    "    game['DefensiveTeam'] = game['DefensiveTeam'].map(team_map)\n",
    "\n",
    "    return game\n",
    "\n",
    "def create_team0_yardage(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a new column which is the yards gained in the play by team zero. \n",
    "    It is negative if team 1 is in posession and gains yards.\n",
    "    \"\"\"\n",
    "    game['team0_yards'] = np.where(game['posteam'] == 0, game['Yards.Gained'], -game['Yards.Gained'])\n",
    "\n",
    "    return game\n",
    "\n",
    "def no_overtime(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Discard all data on overtime periods. \n",
    "    Will result in another Dataframe\n",
    "    \"\"\"\n",
    "    game = game[game[\"qtr\"]!=5]\n",
    "    return game\n",
    "    \n",
    "\n",
    "# Of note: Yards.Gained\n",
    "# TODO: column of yards gained for team 0, when team 1 gains yards, value is negative\n",
    "# TODO: keep nans in until you calculate time per play\n",
    "#   then delete those rows like before and replace nans in time per play with\n",
    "#   average time per play in that game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in games, separate into individual games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find an activated virtualenv (required).\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kagglehub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read in the super long data set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Download latest version\u001b[39;00m\n\u001b[1;32m      5\u001b[0m path \u001b[38;5;241m=\u001b[39m kagglehub\u001b[38;5;241m.\u001b[39mdataset_download(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxhorowitz/nflplaybyplay2009to2016\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kagglehub'"
     ]
    }
   ],
   "source": [
    "# Read in the super long data set\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"maxhorowitz/nflplaybyplay2009to2016\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"NFLPlaybyPlay2015.csv\")\n",
    "df.drop(columns=['Unnamed: 0', 'Season'], inplace=True)\n",
    "\n",
    "games = separate_games(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean rows and add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, game in enumerate(games):\n",
    "    games[i] = no_overtime(game)\n",
    "    games[i] = calculate_time_per_play(game)\n",
    "    games[i] = drop_unnecessary_rows(games[i])\n",
    "    games[i] = encode_teams(games[i])\n",
    "    games[i] = create_team0_yardage(games[i])\n",
    "\n",
    "game = games[30]\n",
    "\n",
    "print(game['posteam'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_columns = ['team0_yards', 'play_time', 'posteam', 'DefensiveTeam']\n",
    "               \n",
    "# TODO: maybe it is easier to calculate team0 yards with 'PosTeamScore'andd'DefTeamScore'.\n",
    "# We could also choose to always label the team0 as the home team 'posteam', 'DefensiveTeam', 'GameID']\n",
    "# TODO: check if diff is forward or backward, and decide which one we want\n",
    "\n",
    "# Check for missing values in these key columns\n",
    "missing_values = game[key_columns].isnull().sum()\n",
    "print(\"Missing values in key columns:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "* Respects chronological order, i.e., training set includes games from earlierin the seasons while the test set only later games\n",
    "* Avoids leakage from future games into the training set\n",
    "* Even though our focus in on modeling the play-by-play sequences within each game and sequential dependencies are confined to within each game, a time-based split might be better than a random one for the following reasons:\n",
    "    * If there's evidence that game dynamics change over the season then making sure training games come from an earlier period than test games can better simulate a forecasting scenario\n",
    "    * Also, in practice, if we're ultimately interested in predicting future plays or games, a time-based split will more closely mimic the conditions under which the model is deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check 'Date' is a datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort the DataFrame by date and then separate games\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# Separate games based on the sorted order\n",
    "games = separate_games(df)\n",
    "\n",
    "# Get dates for each game\n",
    "game_dates = [game.iloc[0]['Date'] for game in games]\n",
    "\n",
    "# Find the cutoff index: 80% of the games as training\n",
    "cutoff_index = int(len(games) * 0.8)\n",
    "\n",
    "# Split games based on sorted order\n",
    "train_games = games[:cutoff_index]\n",
    "test_games = games[cutoff_index:]\n",
    "\n",
    "# Get dates for each game\n",
    "train_dates = [game.iloc[0]['Date'] for game in train_games]\n",
    "test_dates = [game.iloc[0]['Date'] for game in test_games]\n",
    "\n",
    "max_train_date = max(train_dates)\n",
    "min_test_date = min(test_dates)\n",
    "\n",
    "print(\"Training set date range:\", min(train_dates), \"to\", max_train_date)\n",
    "print(\"Test set date range:\", min_test_date, \"to\", max(test_dates))\n",
    "\n",
    "# If the training and test sets share the same boundary date, remove those games from test_games\n",
    "if max_train_date == min_test_date:\n",
    "    test_games = [game for game in test_games if game.iloc[0]['Date'] > max_train_date]\n",
    "    test_dates = [game.iloc[0]['Date'] for game in test_games]\n",
    "    print(\"Adjusted Test set date range:\", min(test_dates), \"to\", max(test_dates))\n",
    "\n",
    "# Final verification: ensure no overlap\n",
    "assert max(train_dates) < min(test_dates), \"There is still an overlap between training and test sets!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat(train_games, ignore_index=True)\n",
    "test_df = pd.concat(test_games, ignore_index=True)\n",
    "train_df.to_csv(\"NFLTrain2015.csv\", index=False)\n",
    "test_df.to_csv(\"NFLTest2015.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"NFL Play by Play 2009-2016 (v3).csv\")\n",
    "\n",
    "#Pick a Home team and index the data on games where they are the home team.\n",
    "\n",
    "df = df[df[\"HomeTeam\"]==\"DET\"]\n",
    "\n",
    "games = separate_games(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"GameID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, game in enumerate(games):\n",
    "    games[i] = no_overtime(game)\n",
    "    games[i] = calculate_time_per_play(game)\n",
    "    games[i] = drop_unnecessary_rows(games[i])\n",
    "    games[i] = encode_teams(games[i])\n",
    "    games[i] = create_team0_yardage(games[i])\n",
    "\n",
    "game = games[30]\n",
    "\n",
    "print(game['posteam'].unique())\n",
    "print(game[\"team0_yards\"].unique())\n",
    "\n",
    "print(type(games[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_columns = ['team0_yards', 'play_time', 'posteam', 'DefensiveTeam']\n",
    "               \n",
    "# TODO: maybe it is easier to calculate team0 yards with 'PosTeamScore'andd'DefTeamScore'.\n",
    "# We could also choose to always label the team0 as the home team 'posteam', 'DefensiveTeam', 'GameID']\n",
    "# TODO: check if diff is forward or backward, and decide which one we want\n",
    "\n",
    "# Check for missing values in these key columns\n",
    "missing_values = game[key_columns].isnull().sum()\n",
    "print(\"Missing values in key columns:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Double check 'Date' is a datetime object\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# # Sort the DataFrame by date and then separate games\n",
    "# df = df.sort_values(by='Date')\n",
    "\n",
    "# # Separate games based on the sorted order\n",
    "# games = separate_games(df)\n",
    "\n",
    "# # Get dates for each game\n",
    "# game_dates = [game.iloc[0]['Date'] for game in games]\n",
    "\n",
    "# # Find the cutoff index: 80% of the games as training\n",
    "# cutoff_index = int(len(games) * 0.8)\n",
    "\n",
    "# # Split games based on sorted order\n",
    "# train_games = games[:cutoff_index]\n",
    "# test_games = games[cutoff_index:]\n",
    "\n",
    "# # Get dates for each game\n",
    "# train_dates = [game.iloc[0]['Date'] for game in train_games]\n",
    "# test_dates = [game.iloc[0]['Date'] for game in test_games]\n",
    "\n",
    "# max_train_date = max(train_dates)\n",
    "# min_test_date = min(test_dates)\n",
    "\n",
    "# print(\"Training set date range:\", min(train_dates), \"to\", max_train_date)\n",
    "# print(\"Test set date range:\", min_test_date, \"to\", max(test_dates))\n",
    "\n",
    "# # If the training and test sets share the same boundary date, remove those games from test_games\n",
    "# if max_train_date == min_test_date:\n",
    "#     test_games = [game for game in test_games if game.iloc[0]['Date'] > max_train_date]\n",
    "#     test_dates = [game.iloc[0]['Date'] for game in test_games]\n",
    "#     print(\"Adjusted Test set date range:\", min(test_dates), \"to\", max(test_dates))\n",
    "\n",
    "# # Final verification: ensure no overlap\n",
    "# assert max(train_dates) < min(test_dates), \"There is still an overlap between training and test sets!\"\n",
    "\n",
    "# train_df = pd.concat(train_games, ignore_index=True)\n",
    "# test_df = pd.concat(test_games, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split based off halves of games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell for messing around and testing stuff out\n",
    "\n",
    "print(game[\"team0_yards\"].unique())\n",
    "\n",
    "game[game[\"team0_yards\"]==-11][\"desc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dict()\n",
    "\n",
    "for i, game in enumerate(games):\n",
    "    gameid = game[\"GameID\"][0]\n",
    "    dataset[gameid] = []\n",
    "    dataset[gameid].append(game[game[\"qtr\"].isin((1,2))][\"team0_yards\"].to_numpy())\n",
    "    dataset[gameid].append(game[game[\"qtr\"].isin((3,4))][\"team0_yards\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the gama data\n",
    "import pickle\n",
    "\n",
    "filename = \"games.pkl\"\n",
    "with open(filename, \"wb\") as file:\n",
    "    pickle.dump(dataset, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of team0_yards\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(train_df['team0_yards'], bins=30, edgecolor='k', alpha=0.75)\n",
    "plt.xlabel('Team 0 Yards')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Team 0 Yards Gained')\n",
    "plt.savefig('team0_yards_distribution.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of play_time\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(train_df['play_time'], bins=30, edgecolor='k', alpha=0.75)\n",
    "plt.xlabel('Play Time (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Play Time per Play')\n",
    "plt.savefig('play_time_distribution.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of play_time vs. team0_yards\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(train_df['play_time'], train_df['team0_yards'], alpha=0.75)\n",
    "plt.xlabel('Play Time (seconds)')\n",
    "plt.ylabel('Team 0 Yards')\n",
    "plt.title('Play Time vs. Team 0 Yards')\n",
    "plt.savefig('play_time_vs_yards.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Analysis: Correlation heatmap of key columns\n",
    "key_columns = ['team0_yards', 'play_time']\n",
    "corr_matrix = games[0][key_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation between Key Features\")\n",
    "plt.savefig(\"key_features_correlation.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
