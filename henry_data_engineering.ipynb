{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Separate Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "End quarter is included as a row of mostly NANs. In column 'desc', this is noted as \"END QUARTER ...\", i.e. \"END QUARTER 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_games(df: pd.DataFrame) -> list[pd.DataFrame]:\n",
    "    \"\"\"Separate dataframe into separate games via the game ID. Place into a \n",
    "    list of games. Indices are reindexed so plays are numbered, starting with 0\n",
    "    \"\"\"\n",
    "    games = [df[df['GameID'] == value].reset_index(drop=True) for value in df['GameID'].unique()]\n",
    "        \n",
    "    return games\n",
    "\n",
    "def calculate_time_per_play(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a new column which is the time each play took.\n",
    "    Kicks will have NANs in the new play_time column, which should make them easy to remove\n",
    "    \"\"\"\n",
    "    game['play_time'] = -game['TimeSecs'].diff()\n",
    "\n",
    "    return game\n",
    "\n",
    "\n",
    "def drop_unnecessary_rows(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"The end of each quarter is its own row. Same with timeouts\n",
    "    and the end of the game. Other values are mostly NANs.\n",
    "    This removes all of those unhelpful rows and reindexes\n",
    "\n",
    "    NOTE: plays must be indexed starting with their first play\n",
    "    TODO: Might be able to just drop rows with missing posteam\n",
    "    \"\"\"\n",
    "    # find indices\n",
    "    game.dropna(subset=['posteam', 'play_time'], inplace=True)\n",
    "    # reset index\n",
    "    game = game.reset_index(drop=True)\n",
    "\n",
    "    return game\n",
    "\n",
    "def encode_teams(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Change all team names to just 0s or 1s. This won't be retraceable if you are\n",
    "    looking for a game with a specific team playing.\n",
    "    \"\"\"\n",
    "    teams = game['posteam'].unique()\n",
    "    if len(teams) != 2:\n",
    "        print(teams)\n",
    "        raise ValueError(\"Dataset has not been properly cleaned. There are more than 2 values in posteam.\")\n",
    "    \n",
    "    team_map = {team:i for i, team in enumerate(teams)}\n",
    "    game['posteam'] = game['posteam'].map(team_map)\n",
    "    game['DefensiveTeam'] = game['DefensiveTeam'].map(team_map)\n",
    "\n",
    "    return game\n",
    "\n",
    "def create_team0_yardage(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a new column which is the yards gained in the play by team zero. \n",
    "    It is negative if team 1 is in posession and gains yards.\n",
    "    \"\"\"\n",
    "    game['team0_yards'] = np.where(game['posteam'] == 0, game['Yards.Gained'], -game['Yards.Gained'])\n",
    "\n",
    "    return game\n",
    "\n",
    "\n",
    "# Of note: Yards.Gained\n",
    "# TODO: column of yards gained for team 0, when team 1 gains yards, value is negative\n",
    "# TODO: keep nans in until you calculate time per play\n",
    "#   then delete those rows like before and replace nans in time per play with\n",
    "#   average time per play in that game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in games, separate into individual games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25898/2432165581.py:1: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"NFLPlaybyPlay2015.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"NFLPlaybyPlay2015.csv\")\n",
    "df.drop(columns=['Unnamed: 0', 'Season'], inplace=True)\n",
    "\n",
    "games = separate_games(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean rows and add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "for i, game in enumerate(games):\n",
    "    games[i] = calculate_time_per_play(game)\n",
    "    games[i] = drop_unnecessary_rows(games[i])\n",
    "    games[i] = encode_teams(games[i])\n",
    "    games[i] = create_team0_yardage(games[i])\n",
    "\n",
    "game = games[30]\n",
    "\n",
    "print(game['posteam'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in key columns:\n",
      " team0_yards      0\n",
      "play_time        0\n",
      "posteam          0\n",
      "DefensiveTeam    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "key_columns = ['team0_yards', 'play_time', 'posteam', 'DefensiveTeam']\n",
    "               \n",
    "# TODO: maybe it is easier to calculate team0 yards with 'PosTeamScore'andd'DefTeamScore'.\n",
    "# We could also choose to always label the team0 as the home team 'posteam', 'DefensiveTeam', 'GameID']\n",
    "# TODO: check if diff is forward or backward, and decide which one we want\n",
    "\n",
    "# Check for missing values in these key columns\n",
    "missing_values = game[key_columns].isnull().sum()\n",
    "print(\"Missing values in key columns:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "* Respects chronological order, i.e., training set includes games from earlierin the seasons while the test set only later games\n",
    "* Avoids leakage from future games into the training set\n",
    "* Even though our focus in on modeling the play-by-play sequences within each game and sequential dependencies are confined to within each game, a time-based split might be better than a random one for the following reasons:\n",
    "    * If there's evidence that game dynamics change over the season then making sure training games come from an earlier period than test games can better simulate a forecasting scenario\n",
    "    * Also, in practice, if we're ultimately interested in predicting future plays or games, a time-based split will more closely mimic the conditions under which the model is deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set date range: 2015-09-10 00:00:00 to 2015-12-13 00:00:00\n",
      "Test set date range: 2015-12-13 00:00:00 to 2016-01-03 00:00:00\n",
      "Adjusted Test set date range: 2015-12-14 00:00:00 to 2016-01-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Double check 'Date' is a datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort the DataFrame by date and then separate games\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# Separate games based on the sorted order\n",
    "games = separate_games(df)\n",
    "\n",
    "# Get dates for each game\n",
    "game_dates = [game.iloc[0]['Date'] for game in games]\n",
    "\n",
    "# Find the cutoff index: 80% of the games as training\n",
    "cutoff_index = int(len(games) * 0.8)\n",
    "\n",
    "# Split games based on sorted order\n",
    "train_games = games[:cutoff_index]\n",
    "test_games = games[cutoff_index:]\n",
    "\n",
    "# Get dates for each game\n",
    "train_dates = [game.iloc[0]['Date'] for game in train_games]\n",
    "test_dates = [game.iloc[0]['Date'] for game in test_games]\n",
    "\n",
    "max_train_date = max(train_dates)\n",
    "min_test_date = min(test_dates)\n",
    "\n",
    "print(\"Training set date range:\", min(train_dates), \"to\", max_train_date)\n",
    "print(\"Test set date range:\", min_test_date, \"to\", max(test_dates))\n",
    "\n",
    "# If the training and test sets share the same boundary date, remove those games from test_games\n",
    "if max_train_date == min_test_date:\n",
    "    test_games = [game for game in test_games if game.iloc[0]['Date'] > max_train_date]\n",
    "    test_dates = [game.iloc[0]['Date'] for game in test_games]\n",
    "    print(\"Adjusted Test set date range:\", min(test_dates), \"to\", max(test_dates))\n",
    "\n",
    "# Final verification: ensure no overlap\n",
    "assert max(train_dates) < min(test_dates), \"There is still an overlap between training and test sets!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat(train_games, ignore_index=True)\n",
    "test_df = pd.concat(test_games, ignore_index=True)\n",
    "train_df.to_csv(\"NFLTrain2015.csv\", index=False)\n",
    "test_df.to_csv(\"NFLTest2015.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
