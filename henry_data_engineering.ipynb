{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Separate Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "End quarter is included as a row of mostly NANs. In column 'desc', this is noted as \"END QUARTER ...\", i.e. \"END QUARTER 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_games(df: pd.DataFrame) -> list[pd.DataFrame]:\n",
    "    \"\"\"Separate dataframe into separate games via the game ID. Place into a \n",
    "    list of games. Indices are reindexed so plays are numbered, starting with 0\n",
    "    \"\"\"\n",
    "    games = [df[df['GameID'] == value].reset_index(drop=True) for value in df['GameID'].unique()]\n",
    "        \n",
    "    return games\n",
    "\n",
    "def separate_years(df: pd.DataFrame) -> list[pd.DataFrame]:\n",
    "    \"\"\"Separates the games by which season in which they occured. Outputs a list of seasons.\"\"\"\n",
    "    seasons = [df[df['Season'] == value].reset_index(drop=True) for value in df['Season'].unique()]\n",
    "    \n",
    "    return seasons\n",
    "\n",
    "def calculate_time_per_play(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a new column which is the time each play took.\n",
    "    Kicks will have NANs in the new play_time column, which should make them easy to remove\n",
    "    \"\"\"\n",
    "    game['play_time'] = -game['TimeSecs'].diff()\n",
    "\n",
    "    return game\n",
    "\n",
    "\n",
    "def drop_unnecessary_rows(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"The end of each quarter is its own row. Same with timeouts\n",
    "    and the end of the game. Other values are mostly NANs.\n",
    "    This removes all of those unhelpful rows and reindexes\n",
    "\n",
    "    NOTE: plays must be indexed starting with their first play\n",
    "    TODO: Might be able to just drop rows with missing posteam\n",
    "    \"\"\"\n",
    "    # find indices\n",
    "    game.dropna(subset=['posteam', 'play_time'], inplace=True)\n",
    "    # reset index\n",
    "    game = game.reset_index(drop=True)\n",
    "\n",
    "    return game\n",
    "\n",
    "def encode_teams(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Change all team names to just 0s or 1s. This won't be retraceable if you are\n",
    "    looking for a game with a specific team playing.\n",
    "    \"\"\"\n",
    "    teams = game['posteam'].unique()\n",
    "    if len(teams) != 2:\n",
    "        print(teams)\n",
    "        raise ValueError(\"Dataset has not been properly cleaned. There are more than 2 values in posteam.\")\n",
    "    \n",
    "    team_map = {team:i for i, team in enumerate(teams)}\n",
    "    game['posteam'] = game['posteam'].map(team_map)\n",
    "    game['DefensiveTeam'] = game['DefensiveTeam'].map(team_map)\n",
    "\n",
    "    return game\n",
    "\n",
    "def create_team0_yardage(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a new column which is the yards gained in the play by team zero. \n",
    "    It is negative if team 1 is in posession and gains yards.\n",
    "    \"\"\"\n",
    "    game['team0_yards'] = np.where(game['posteam'] == 0, game['Yards.Gained'], -game['Yards.Gained'])\n",
    "\n",
    "    return game\n",
    "\n",
    "def no_overtime(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Discard all data on overtime periods. \n",
    "    Will result in another Dataframe\n",
    "    \"\"\"\n",
    "    game = game[game[\"qtr\"]!=5]\n",
    "    return game\n",
    "    \n",
    "\n",
    "# Of note: Yards.Gained\n",
    "# TODO: column of yards gained for team 0, when team 1 gains yards, value is negative\n",
    "# TODO: keep nans in until you calculate time per play\n",
    "#   then delete those rows like before and replace nans in time per play with\n",
    "#   average time per play in that game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in games, separate into individual games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/t2l5ty511_gcgj29jwr9n4sh0000gn/T/ipykernel_82609/2432165581.py:1: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"NFLPlaybyPlay2015.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"NFLPlaybyPlay2015.csv\")\n",
    "df.drop(columns=['Unnamed: 0', 'Season'], inplace=True)\n",
    "\n",
    "games = separate_games(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean rows and add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "for i, game in enumerate(games):\n",
    "    games[i] = no_overtime(game)\n",
    "    games[i] = calculate_time_per_play(game)\n",
    "    games[i] = drop_unnecessary_rows(games[i])\n",
    "    games[i] = encode_teams(games[i])\n",
    "    games[i] = create_team0_yardage(games[i])\n",
    "\n",
    "game = games[30]\n",
    "\n",
    "print(game['posteam'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in key columns:\n",
      " team0_yards      0\n",
      "play_time        0\n",
      "posteam          0\n",
      "DefensiveTeam    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "key_columns = ['team0_yards', 'play_time', 'posteam', 'DefensiveTeam']\n",
    "               \n",
    "# TODO: maybe it is easier to calculate team0 yards with 'PosTeamScore'andd'DefTeamScore'.\n",
    "# We could also choose to always label the team0 as the home team 'posteam', 'DefensiveTeam', 'GameID']\n",
    "# TODO: check if diff is forward or backward, and decide which one we want\n",
    "\n",
    "# Check for missing values in these key columns\n",
    "missing_values = game[key_columns].isnull().sum()\n",
    "print(\"Missing values in key columns:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "* Respects chronological order, i.e., training set includes games from earlierin the seasons while the test set only later games\n",
    "* Avoids leakage from future games into the training set\n",
    "* Even though our focus in on modeling the play-by-play sequences within each game and sequential dependencies are confined to within each game, a time-based split might be better than a random one for the following reasons:\n",
    "    * If there's evidence that game dynamics change over the season then making sure training games come from an earlier period than test games can better simulate a forecasting scenario\n",
    "    * Also, in practice, if we're ultimately interested in predicting future plays or games, a time-based split will more closely mimic the conditions under which the model is deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set date range: 2015-09-10 00:00:00 to 2015-12-13 00:00:00\n",
      "Test set date range: 2015-12-13 00:00:00 to 2016-01-03 00:00:00\n",
      "Adjusted Test set date range: 2015-12-14 00:00:00 to 2016-01-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Double check 'Date' is a datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort the DataFrame by date and then separate games\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# Separate games based on the sorted order\n",
    "games = separate_games(df)\n",
    "\n",
    "# Get dates for each game\n",
    "game_dates = [game.iloc[0]['Date'] for game in games]\n",
    "\n",
    "# Find the cutoff index: 80% of the games as training\n",
    "cutoff_index = int(len(games) * 0.8)\n",
    "\n",
    "# Split games based on sorted order\n",
    "train_games = games[:cutoff_index]\n",
    "test_games = games[cutoff_index:]\n",
    "\n",
    "# Get dates for each game\n",
    "train_dates = [game.iloc[0]['Date'] for game in train_games]\n",
    "test_dates = [game.iloc[0]['Date'] for game in test_games]\n",
    "\n",
    "max_train_date = max(train_dates)\n",
    "min_test_date = min(test_dates)\n",
    "\n",
    "print(\"Training set date range:\", min(train_dates), \"to\", max_train_date)\n",
    "print(\"Test set date range:\", min_test_date, \"to\", max(test_dates))\n",
    "\n",
    "# If the training and test sets share the same boundary date, remove those games from test_games\n",
    "if max_train_date == min_test_date:\n",
    "    test_games = [game for game in test_games if game.iloc[0]['Date'] > max_train_date]\n",
    "    test_dates = [game.iloc[0]['Date'] for game in test_games]\n",
    "    print(\"Adjusted Test set date range:\", min(test_dates), \"to\", max(test_dates))\n",
    "\n",
    "# Final verification: ensure no overlap\n",
    "assert max(train_dates) < min(test_dates), \"There is still an overlap between training and test sets!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat(train_games, ignore_index=True)\n",
    "test_df = pd.concat(test_games, ignore_index=True)\n",
    "train_df.to_csv(\"NFLTrain2015.csv\", index=False)\n",
    "test_df.to_csv(\"NFLTest2015.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GameID</th>\n",
       "      <th>Drive</th>\n",
       "      <th>qtr</th>\n",
       "      <th>down</th>\n",
       "      <th>time</th>\n",
       "      <th>TimeUnder</th>\n",
       "      <th>TimeSecs</th>\n",
       "      <th>PlayTimeDiff</th>\n",
       "      <th>SideofField</th>\n",
       "      <th>...</th>\n",
       "      <th>ChalReplayResult</th>\n",
       "      <th>Accepted.Penalty</th>\n",
       "      <th>PenalizedTeam</th>\n",
       "      <th>PenaltyType</th>\n",
       "      <th>PenalizedPlayer</th>\n",
       "      <th>Penalty.Yards</th>\n",
       "      <th>PosTeamScore</th>\n",
       "      <th>DefTeamScore</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>AbsScoreDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-09-10</td>\n",
       "      <td>2015091000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:00</td>\n",
       "      <td>15</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-09-10</td>\n",
       "      <td>2015091000</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>02:59</td>\n",
       "      <td>3</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>PIT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-10</td>\n",
       "      <td>2015091000</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>02:15</td>\n",
       "      <td>3</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>PIT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-10</td>\n",
       "      <td>2015091000</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01:31</td>\n",
       "      <td>2</td>\n",
       "      <td>991.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-10</td>\n",
       "      <td>2015091000</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01:14</td>\n",
       "      <td>2</td>\n",
       "      <td>974.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36828</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>2015121309</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12:25</td>\n",
       "      <td>13</td>\n",
       "      <td>745.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>DET</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36829</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>2015121309</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:14</td>\n",
       "      <td>13</td>\n",
       "      <td>734.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DET</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36830</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>2015121309</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:14</td>\n",
       "      <td>13</td>\n",
       "      <td>734.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36831</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>2015121309</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>STL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36832</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>2015121309</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12:08</td>\n",
       "      <td>13</td>\n",
       "      <td>1628.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>STL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36833 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date      GameID  Drive  qtr  down   time  TimeUnder  TimeSecs  \\\n",
       "0     2015-09-10  2015091000      1    1   NaN  15:00         15    3600.0   \n",
       "1     2015-09-10  2015091000     12    3   2.0  02:59          3    1079.0   \n",
       "2     2015-09-10  2015091000     12    3   3.0  02:15          3    1035.0   \n",
       "3     2015-09-10  2015091000     12    3   1.0  01:31          2     991.0   \n",
       "4     2015-09-10  2015091000     12    3   1.0  01:14          2     974.0   \n",
       "...          ...         ...    ...  ...   ...    ...        ...       ...   \n",
       "36828 2015-12-13  2015121309     17    4   2.0  12:25         13     745.0   \n",
       "36829 2015-12-13  2015121309     17    4   NaN  12:14         13     734.0   \n",
       "36830 2015-12-13  2015121309     18    4   NaN  12:14         13     734.0   \n",
       "36831 2015-12-13  2015121309     17    3   NaN  00:00          0     900.0   \n",
       "36832 2015-12-13  2015121309     13    3   4.0  12:08         13    1628.0   \n",
       "\n",
       "       PlayTimeDiff SideofField  ...  ChalReplayResult  Accepted.Penalty  \\\n",
       "0               0.0          NE  ...               NaN                 0   \n",
       "1              44.0         PIT  ...               NaN                 0   \n",
       "2              44.0         PIT  ...               NaN                 0   \n",
       "3              44.0          NE  ...               NaN                 0   \n",
       "4              17.0          NE  ...               NaN                 0   \n",
       "...             ...         ...  ...               ...               ...   \n",
       "36828          27.0         DET  ...               NaN                 0   \n",
       "36829          11.0         DET  ...               NaN                 0   \n",
       "36830           0.0         STL  ...               NaN                 0   \n",
       "36831          19.0         STL  ...               NaN                 0   \n",
       "36832          36.0         STL  ...               NaN                 0   \n",
       "\n",
       "       PenalizedTeam  PenaltyType  PenalizedPlayer  Penalty.Yards  \\\n",
       "0                NaN          NaN              NaN              0   \n",
       "1                NaN          NaN              NaN              0   \n",
       "2                NaN          NaN              NaN              0   \n",
       "3                NaN          NaN              NaN              0   \n",
       "4                NaN          NaN              NaN              0   \n",
       "...              ...          ...              ...            ...   \n",
       "36828            NaN          NaN              NaN              0   \n",
       "36829            NaN          NaN              NaN              0   \n",
       "36830            NaN          NaN              NaN              0   \n",
       "36831            NaN          NaN              NaN              0   \n",
       "36832            NaN          NaN              NaN              0   \n",
       "\n",
       "      PosTeamScore DefTeamScore ScoreDiff  AbsScoreDiff  \n",
       "0              0.0          0.0       0.0           0.0  \n",
       "1             11.0         21.0     -10.0          10.0  \n",
       "2             11.0         21.0     -10.0          10.0  \n",
       "3             11.0         21.0     -10.0          10.0  \n",
       "4             11.0         21.0     -10.0          10.0  \n",
       "...            ...          ...       ...           ...  \n",
       "36828         19.0          7.0      12.0          12.0  \n",
       "36829         20.0          7.0      13.0          13.0  \n",
       "36830          7.0         20.0     -13.0          13.0  \n",
       "36831          NaN          NaN       NaN           NaN  \n",
       "36832          6.0          0.0       6.0           6.0  \n",
       "\n",
       "[36833 rows x 64 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/t2l5ty511_gcgj29jwr9n4sh0000gn/T/ipykernel_82609/1113220281.py:1: DtypeWarning: Columns (25,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"NFL Play by Play 2009-2016 (v3).csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"NFL Play by Play 2009-2016 (v3).csv\")\n",
    "\n",
    "#Pick a Home team and index the data on games where they are the home team.\n",
    "\n",
    "df = df[df[\"HomeTeam\"]==\"DET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"GameID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "for i, game in enumerate(games):\n",
    "    games[i] = no_overtime(game)\n",
    "    games[i] = calculate_time_per_play(game)\n",
    "    games[i] = drop_unnecessary_rows(games[i])\n",
    "    games[i] = encode_teams(games[i])\n",
    "    games[i] = create_team0_yardage(games[i])\n",
    "\n",
    "game = games[30]\n",
    "\n",
    "print(game['posteam'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in key columns:\n",
      " team0_yards      0\n",
      "play_time        0\n",
      "posteam          0\n",
      "DefensiveTeam    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "key_columns = ['team0_yards', 'play_time', 'posteam', 'DefensiveTeam']\n",
    "               \n",
    "# TODO: maybe it is easier to calculate team0 yards with 'PosTeamScore'andd'DefTeamScore'.\n",
    "# We could also choose to always label the team0 as the home team 'posteam', 'DefensiveTeam', 'GameID']\n",
    "# TODO: check if diff is forward or backward, and decide which one we want\n",
    "\n",
    "# Check for missing values in these key columns\n",
    "missing_values = game[key_columns].isnull().sum()\n",
    "print(\"Missing values in key columns:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = separate_years(df)\n",
    "games = separate_games(seasons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.floor(2/3 * len(games)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
