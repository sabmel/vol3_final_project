{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Separate Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "End quarter is included as a row of mostly NANs. In column 'desc', this is noted as \"END QUARTER ...\", i.e. \"END QUARTER 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_games(df: pd.DataFrame) -> list[pd.DataFrame]:\n",
    "    \"\"\"Separate dataframe into separate games via the game ID. Place into a \n",
    "    list of games. Indices are reindexed so plays are numbered, starting with 0\n",
    "    \"\"\"\n",
    "    games = [df[df['GameID'] == value].reset_index(drop=True) for value in df['GameID'].unique()]\n",
    "        \n",
    "    return games\n",
    "\n",
    "def separate_years(df: pd.DataFrame) -> list[pd.DataFrame]:\n",
    "    \"\"\"Separates the games by which season in which they occured. Outputs a list of seasons.\"\"\"\n",
    "    seasons = [df[df['Season'] == value].reset_index(drop=True) for value in df['Season'].unique()]\n",
    "    \n",
    "    return seasons\n",
    "\n",
    "def calculate_time_per_play(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a new column which is the time each play took.\n",
    "    Kicks will have NANs in the new play_time column, which should make them easy to remove\n",
    "    \"\"\"\n",
    "    game['play_time'] = -game['TimeSecs'].diff()\n",
    "\n",
    "    return game\n",
    "\n",
    "\n",
    "def drop_unnecessary_rows(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"The end of each quarter is its own row. Same with timeouts\n",
    "    and the end of the game. Other values are mostly NANs.\n",
    "    This removes all of those unhelpful rows and reindexes\n",
    "\n",
    "    NOTE: plays must be indexed starting with their first play\n",
    "    TODO: Might be able to just drop rows with missing posteam\n",
    "    \"\"\"\n",
    "    # find indices\n",
    "    game.dropna(subset=['posteam', 'play_time'], inplace=True)\n",
    "    # reset index\n",
    "    game = game.reset_index(drop=True)\n",
    "\n",
    "    return game\n",
    "\n",
    "def encode_teams(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Change all team names to just 0s or 1s. This won't be retraceable if you are\n",
    "    looking for a game with a specific team playing.\n",
    "    \"\"\"\n",
    "    teams = game['posteam'].unique()\n",
    "    if len(teams) != 2:\n",
    "        print(teams)\n",
    "        raise ValueError(\"Dataset has not been properly cleaned. There are more than 2 values in posteam.\")\n",
    "    \n",
    "    team_map = {team:i for i, team in enumerate(teams)}\n",
    "    game['posteam'] = game['posteam'].map(team_map)\n",
    "    game['DefensiveTeam'] = game['DefensiveTeam'].map(team_map)\n",
    "\n",
    "    return game\n",
    "\n",
    "def create_team0_yardage(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a new column which is the yards gained in the play by team zero. \n",
    "    It is negative if team 1 is in posession and gains yards.\n",
    "    \"\"\"\n",
    "    game['team0_yards'] = np.where(game['posteam'] == 0, game['Yards.Gained'], -game['Yards.Gained'])\n",
    "\n",
    "    return game\n",
    "\n",
    "def no_overtime(game: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Discard all data on overtime periods. \n",
    "    Will result in another Dataframe\n",
    "    \"\"\"\n",
    "    game = game[game[\"qtr\"]!=5]\n",
    "    return game\n",
    "    \n",
    "\n",
    "# Of note: Yards.Gained\n",
    "# TODO: column of yards gained for team 0, when team 1 gains yards, value is negative\n",
    "# TODO: keep nans in until you calculate time per play\n",
    "#   then delete those rows like before and replace nans in time per play with\n",
    "#   average time per play in that game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in games, separate into individual games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/t2l5ty511_gcgj29jwr9n4sh0000gn/T/ipykernel_7832/2432165581.py:1: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"NFLPlaybyPlay2015.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"NFLPlaybyPlay2015.csv\")\n",
    "df.drop(columns=['Unnamed: 0', 'Season'], inplace=True)\n",
    "\n",
    "games = separate_games(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean rows and add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "for i, game in enumerate(games):\n",
    "    games[i] = no_overtime(game)\n",
    "    games[i] = calculate_time_per_play(game)\n",
    "    games[i] = drop_unnecessary_rows(games[i])\n",
    "    games[i] = encode_teams(games[i])\n",
    "    games[i] = create_team0_yardage(games[i])\n",
    "\n",
    "game = games[30]\n",
    "\n",
    "print(game['posteam'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in key columns:\n",
      " team0_yards      0\n",
      "play_time        0\n",
      "posteam          0\n",
      "DefensiveTeam    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "key_columns = ['team0_yards', 'play_time', 'posteam', 'DefensiveTeam']\n",
    "               \n",
    "# TODO: maybe it is easier to calculate team0 yards with 'PosTeamScore'andd'DefTeamScore'.\n",
    "# We could also choose to always label the team0 as the home team 'posteam', 'DefensiveTeam', 'GameID']\n",
    "# TODO: check if diff is forward or backward, and decide which one we want\n",
    "\n",
    "# Check for missing values in these key columns\n",
    "missing_values = game[key_columns].isnull().sum()\n",
    "print(\"Missing values in key columns:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "* Respects chronological order, i.e., training set includes games from earlierin the seasons while the test set only later games\n",
    "* Avoids leakage from future games into the training set\n",
    "* Even though our focus in on modeling the play-by-play sequences within each game and sequential dependencies are confined to within each game, a time-based split might be better than a random one for the following reasons:\n",
    "    * If there's evidence that game dynamics change over the season then making sure training games come from an earlier period than test games can better simulate a forecasting scenario\n",
    "    * Also, in practice, if we're ultimately interested in predicting future plays or games, a time-based split will more closely mimic the conditions under which the model is deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set date range: 2015-09-10 00:00:00 to 2015-12-13 00:00:00\n",
      "Test set date range: 2015-12-13 00:00:00 to 2016-01-03 00:00:00\n",
      "Adjusted Test set date range: 2015-12-14 00:00:00 to 2016-01-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Double check 'Date' is a datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort the DataFrame by date and then separate games\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# Separate games based on the sorted order\n",
    "games = separate_games(df)\n",
    "\n",
    "# Get dates for each game\n",
    "game_dates = [game.iloc[0]['Date'] for game in games]\n",
    "\n",
    "# Find the cutoff index: 80% of the games as training\n",
    "cutoff_index = int(len(games) * 0.8)\n",
    "\n",
    "# Split games based on sorted order\n",
    "train_games = games[:cutoff_index]\n",
    "test_games = games[cutoff_index:]\n",
    "\n",
    "# Get dates for each game\n",
    "train_dates = [game.iloc[0]['Date'] for game in train_games]\n",
    "test_dates = [game.iloc[0]['Date'] for game in test_games]\n",
    "\n",
    "max_train_date = max(train_dates)\n",
    "min_test_date = min(test_dates)\n",
    "\n",
    "print(\"Training set date range:\", min(train_dates), \"to\", max_train_date)\n",
    "print(\"Test set date range:\", min_test_date, \"to\", max(test_dates))\n",
    "\n",
    "# If the training and test sets share the same boundary date, remove those games from test_games\n",
    "if max_train_date == min_test_date:\n",
    "    test_games = [game for game in test_games if game.iloc[0]['Date'] > max_train_date]\n",
    "    test_dates = [game.iloc[0]['Date'] for game in test_games]\n",
    "    print(\"Adjusted Test set date range:\", min(test_dates), \"to\", max(test_dates))\n",
    "\n",
    "# Final verification: ensure no overlap\n",
    "assert max(train_dates) < min(test_dates), \"There is still an overlap between training and test sets!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat(train_games, ignore_index=True)\n",
    "test_df = pd.concat(test_games, ignore_index=True)\n",
    "train_df.to_csv(\"NFLTrain2015.csv\", index=False)\n",
    "test_df.to_csv(\"NFLTest2015.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/t2l5ty511_gcgj29jwr9n4sh0000gn/T/ipykernel_7832/2940291245.py:1: DtypeWarning: Columns (25,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"NFL Play by Play 2009-2016 (v3).csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"NFL Play by Play 2009-2016 (v3).csv\")\n",
    "\n",
    "#Pick a Home team and index the data on games where they are the home team.\n",
    "\n",
    "df = df[df[\"HomeTeam\"]==\"DET\"]\n",
    "\n",
    "games = separate_games(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"GameID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[  3   5   1   9   0 -12  -1  -7  49   2 -16  -5 -44  31  13   8  18   7\n",
      "   4  -9  -2 -39  20  -8  -4 -11  16  14  22   6 -26  12 -14  26  21  11\n",
      " -23  -6 -15 -22 -10  10]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "for i, game in enumerate(games):\n",
    "    games[i] = no_overtime(game)\n",
    "    games[i] = calculate_time_per_play(game)\n",
    "    games[i] = drop_unnecessary_rows(games[i])\n",
    "    games[i] = encode_teams(games[i])\n",
    "    games[i] = create_team0_yardage(games[i])\n",
    "\n",
    "game = games[30]\n",
    "\n",
    "print(game['posteam'].unique())\n",
    "print(game[\"team0_yards\"].unique())\n",
    "\n",
    "print(type(games[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in key columns:\n",
      " team0_yards      0\n",
      "play_time        0\n",
      "posteam          0\n",
      "DefensiveTeam    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "key_columns = ['team0_yards', 'play_time', 'posteam', 'DefensiveTeam']\n",
    "               \n",
    "# TODO: maybe it is easier to calculate team0 yards with 'PosTeamScore'andd'DefTeamScore'.\n",
    "# We could also choose to always label the team0 as the home team 'posteam', 'DefensiveTeam', 'GameID']\n",
    "# TODO: check if diff is forward or backward, and decide which one we want\n",
    "\n",
    "# Check for missing values in these key columns\n",
    "missing_values = game[key_columns].isnull().sum()\n",
    "print(\"Missing values in key columns:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Double check 'Date' is a datetime object\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# # Sort the DataFrame by date and then separate games\n",
    "# df = df.sort_values(by='Date')\n",
    "\n",
    "# # Separate games based on the sorted order\n",
    "# games = separate_games(df)\n",
    "\n",
    "# # Get dates for each game\n",
    "# game_dates = [game.iloc[0]['Date'] for game in games]\n",
    "\n",
    "# # Find the cutoff index: 80% of the games as training\n",
    "# cutoff_index = int(len(games) * 0.8)\n",
    "\n",
    "# # Split games based on sorted order\n",
    "# train_games = games[:cutoff_index]\n",
    "# test_games = games[cutoff_index:]\n",
    "\n",
    "# # Get dates for each game\n",
    "# train_dates = [game.iloc[0]['Date'] for game in train_games]\n",
    "# test_dates = [game.iloc[0]['Date'] for game in test_games]\n",
    "\n",
    "# max_train_date = max(train_dates)\n",
    "# min_test_date = min(test_dates)\n",
    "\n",
    "# print(\"Training set date range:\", min(train_dates), \"to\", max_train_date)\n",
    "# print(\"Test set date range:\", min_test_date, \"to\", max(test_dates))\n",
    "\n",
    "# # If the training and test sets share the same boundary date, remove those games from test_games\n",
    "# if max_train_date == min_test_date:\n",
    "#     test_games = [game for game in test_games if game.iloc[0]['Date'] > max_train_date]\n",
    "#     test_dates = [game.iloc[0]['Date'] for game in test_games]\n",
    "#     print(\"Adjusted Test set date range:\", min(test_dates), \"to\", max(test_dates))\n",
    "\n",
    "# # Final verification: ensure no overlap\n",
    "# assert max(train_dates) < min(test_dates), \"There is still an overlap between training and test sets!\"\n",
    "\n",
    "# train_df = pd.concat(train_games, ignore_index=True)\n",
    "# test_df = pd.concat(test_games, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split based off halves of games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6   0  10  -4  -5 -10   5  13   4   2  16  -8 -15  15   9  17   1   3\n",
      "  14  11 -11 -24 -14  -6  -2  -7  24  35   7 -18  -1 -39  -3 -20 -16  12\n",
      "  30 -12 -31  36  23 -13  -9  19]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40     (14:03) (Shotgun) A.Rodgers pass short left to...\n",
       "92     (13:09) A.Rodgers pass short right to G.Alliso...\n",
       "112    (4:48) T.Montgomery right end ran ob at GB 42 ...\n",
       "130    (11:28) A.Rodgers pass short right to J.Nelson...\n",
       "Name: desc, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cell for messing around and testing stuff out\n",
    "\n",
    "print(game[\"team0_yards\"].unique())\n",
    "\n",
    "game[game[\"team0_yards\"]==-11][\"desc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dict()\n",
    "\n",
    "for i, game in enumerate(games):\n",
    "    gameid = game[\"GameID\"][0]\n",
    "    dataset[gameid] = []\n",
    "    dataset[gameid].append(game[game[\"qtr\"].isin((1,2))][\"team0_yards\"].to_numpy())\n",
    "    dataset[gameid].append(game[game[\"qtr\"].isin((3,4))][\"team0_yards\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'team0_yards'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'team0_yards'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Distribution of team0_yards\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam0_yards\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam 0 Yards\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrequency\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'team0_yards'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of team0_yards\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(train_df['team0_yards'], bins=30, edgecolor='k', alpha=0.75)\n",
    "plt.xlabel('Team 0 Yards')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Team 0 Yards Gained')\n",
    "plt.savefig('team0_yards_distribution.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'play_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'play_time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Distribution of play_time\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplay_time\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlay Time (seconds)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrequency\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'play_time'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of play_time\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(train_df['play_time'], bins=30, edgecolor='k', alpha=0.75)\n",
    "plt.xlabel('Play Time (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Play Time per Play')\n",
    "plt.savefig('play_time_distribution.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of play_time vs. team0_yards\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(train_df['play_time'], train_df['team0_yards'], alpha=0.75)\n",
    "plt.xlabel('Play Time (seconds)')\n",
    "plt.ylabel('Team 0 Yards')\n",
    "plt.title('Play Time vs. Team 0 Yards')\n",
    "plt.savefig('play_time_vs_yards.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Analysis: Correlation heatmap of key columns\n",
    "key_columns = ['team0_yards', 'play_time']\n",
    "corr_matrix = games[0][key_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation between Key Features\")\n",
    "plt.savefig(\"key_features_correlation.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
